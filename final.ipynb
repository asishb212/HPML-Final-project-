{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "#Install Dependencies\n",
    "\n",
    "!! Use GPU runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "1fb5956a-e3e3-4c29-d19c-b5efde4cc430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hSetup complete. Using torch 2.0.0+cu118 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15101MB, multi_processor_count=40)\n"
     ]
    }
   ],
   "source": [
    "!pip install -qr requirements.txt  # install dependencies\n",
    "import torch\n",
    "\n",
    "from IPython.display import Image, clear_output \n",
    "\n",
    "# clear_output()\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwJx-2NHsYxT"
   },
   "source": [
    "# Define Model Configuration and Architecture\n",
    "\n",
    "Write a yaml script that defines paths for train and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0kMrAgJ8aBL"
   },
   "source": [
    "# yaml file for training\n",
    "<p></p>\n",
    "train: path to train dataset</p>\n",
    "val: path to validation dataset</p>\n",
    "\n",
    "nc: 4</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUOiNLtMP5aG"
   },
   "source": [
    "# Train Custom YOLOv5 Detector\n",
    "\n",
    "\n",
    "Here, we are able to pass a number of arguments:\n",
    "- **img:** define input image size\n",
    "- **batch:** determine batch size\n",
    "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
    "- **data:** set the path to our yaml file\n",
    "- **cfg:** specify our model configuration\n",
    "- **weights:** specify a custom path to weights. \n",
    "- **name:** result names\n",
    "- **nosave:** only save the final checkpoint\n",
    "- **cache:** cache images for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NcFxRcFdJ_O"
   },
   "outputs": [],
   "source": [
    "# time its performance\n",
    "\"\"\"\n",
    "Parameters for this case:\n",
    "image size = 416\n",
    "batch = 16\n",
    "epochs = 200\n",
    "dataset info = /content/yolov5/data.yaml\n",
    "model configuration = yoloS\n",
    "output directory = yolo5s results\n",
    "\"\"\"\n",
    "%%time\n",
    "%cd /content/yolov5/\n",
    "!python train.py --img 416 --batch 16 --epochs 200 --data /content/yolov5/data.yaml --cfg /content/yolov5/models/yolo5s.yaml --weights '' --name yolov5s_results  --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJVs_4zEeVbF"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOy5KI2ncnWd"
   },
   "outputs": [],
   "source": [
    "# Start tensorboard\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/yolov5/runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C60XAsyv6OPe"
   },
   "outputs": [],
   "source": [
    "%cd /content/yolov5/\n",
    "from utils.plots import plot_results  # plot results.txt as results.png\n",
    "Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)  # view results.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W40tI99_7BcH"
   },
   "outputs": [],
   "source": [
    "# print out an augmented training example\n",
    "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
    "Image(filename='/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3qM6T0W53gh"
   },
   "source": [
    "#Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9nmZZnWOgJ2S"
   },
   "outputs": [],
   "source": [
    "# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n",
    "# use the best weights!\n",
    "!rm -rf /content/run/\n",
    "%mkdir /content/run\n",
    "%cd /content/yolov5/\n",
    "#inputs\n",
    "# weight file\n",
    "# test images\n",
    "!python detect.py --weights /content/best.pt --img 416 --conf 0.4 --source /content/part/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Lw66IOZHjT7r"
   },
   "outputs": [],
   "source": [
    "# to write videos\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Define the folder containing the images\n",
    "folder_path = \"/content/run/\"\n",
    "\n",
    "# Define the output video file name\n",
    "output_video = \"output.avi\"\n",
    "\n",
    "# Get the list of image files in the folder\n",
    "image_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "# Get the first image in the list to use as a reference for the video dimensions\n",
    "img = cv2.imread(image_files[0])\n",
    "height, width, layers = img.shape\n",
    "\n",
    "# Initialize the video writer\n",
    "video = cv2.VideoWriter(output_video, 0, 1, (width, height))\n",
    "\n",
    "# Loop through the image files and add each frame to the video\n",
    "for image_file in image_files:\n",
    "    img = cv2.imread(image_file)\n",
    "    video.write(img)\n",
    "\n",
    "# Release the video writer and destroy all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
